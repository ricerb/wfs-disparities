{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Assign PM2.5 concentrations to Census tracts.\"\"\"\n",
    "\n",
    "from monetio.models import cmaq\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import geopandas\n",
    "from scipy import interpolate\n",
    "\n",
    "import calendar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. interpolate Kirk Baker CMAQ dataset to census tracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_file = \"C:\\\\Users\\\\rrice\\\\OneDrive - Environmental Protection Agency (EPA)\\\\exposure disparities\\\\nhgis0003_shape\\\\US_tract_cenpop_2010.shp\"\n",
    "\n",
    "census_points = geopandas.read_file(census_file, dtype={\"GEOID\": str})\n",
    "\n",
    "# interpolate cmaq outputs to census tract level for every year in the dataset\n",
    "dflist = []\n",
    "\n",
    "for year in range(2006, 2021):\n",
    "    if year in range(2007, 2019):\n",
    "        cmaq_file = f\"C:\\\\Users\\\\rrice\\\\OneDrive - Environmental Protection Agency (EPA)\\\\exposure disparities\\\\CMAQ kirk baker total and no-fire\\\\dailyavgs.{year}.12US2.baseline.ncf\"\n",
    "\n",
    "        cmaq_file_nofire = f\"C:\\\\Users\\\\rrice\\\\OneDrive - Environmental Protection Agency (EPA)\\\\exposure disparities\\\\CMAQ kirk baker total and no-fire\\\\dailyavgs.{year}.12US2.baseline_0fire.ncf\"\n",
    "\n",
    "        # read both cmaq files and interpolate to census tract level\n",
    "\n",
    "        interp_pm_list = []\n",
    "\n",
    "        for file in [cmaq_file, cmaq_file_nofire]:\n",
    "            ds = cmaq.open_dataset(fname=file)\n",
    "\n",
    "            dfpm = (\n",
    "                ds[\"PMIJ\"]\n",
    "                .to_dataframe()\n",
    "                .groupby([\"longitude\", \"latitude\"])\n",
    "                .mean()\n",
    "                .reset_index()\n",
    "            )\n",
    "\n",
    "            interp_pm_list.append(\n",
    "                interpolate.griddata(\n",
    "                    points=dfpm[[\"longitude\", \"latitude\"]],\n",
    "                    values=dfpm[\"PMIJ\"],\n",
    "                    xi=census_points[[\"LONGITUDE\", \"LATITUDE\"]],\n",
    "                    method=\"cubic\",\n",
    "                )\n",
    "            )\n",
    "\n",
    "        dfi = pd.DataFrame(\n",
    "            {\n",
    "                \"GEOID\": census_points[\"GEOID\"],\n",
    "                \"GISJOIN\": census_points[\"GISJOIN\"],\n",
    "                \"PM_total\": interp_pm_list[0],\n",
    "                \"PM_nofire\": interp_pm_list[1],\n",
    "                \"longitude\": census_points[\"LONGITUDE\"],\n",
    "                \"latitude\": census_points[\"LATITUDE\"],\n",
    "            }\n",
    "        )\n",
    "    else:\n",
    "        # initialize dataframe with NaNs for years in stanford dataset that aren't in cmaq dataset\n",
    "        dfi = pd.DataFrame(\n",
    "            {\n",
    "                \"GEOID\": census_points[\"GEOID\"],\n",
    "                \"GISJOIN\": census_points[\"GISJOIN\"],\n",
    "                \"PM_total\": np.nan,\n",
    "                \"PM_nofire\": np.nan,\n",
    "                \"longitude\": census_points[\"LONGITUDE\"],\n",
    "                \"latitude\": census_points[\"LATITUDE\"],\n",
    "            }\n",
    "        )\n",
    "\n",
    "    dfi[\"year\"] = year\n",
    "\n",
    "    dflist.append(dfi)\n",
    "\n",
    "dfe = pd.concat(dflist)\n",
    "dfe[\"PM_wf\"] = dfe[\"PM_total\"] - dfe[\"PM_nofire\"]  # wildfire-specific PM\n",
    "\n",
    "# set negative wildfire PM values to 0\n",
    "dfe.loc[dfe[\"PM_wf\"] < 0, \"PM_wf\"] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 get fasqsd dataset in same format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in FAQSD data\n",
    "\n",
    "dflist = []\n",
    "for year in range(2006, 2020):\n",
    "    dfy = pd.read_csv(\n",
    "        f\"C:\\\\Users\\\\rrice\\\\OneDrive - Environmental Protection Agency (EPA)\\\\exposure disparities\\\\CMAQ FAQSD data\\\\{year}_pm25_daily_average.txt.gz\",\n",
    "        compression=\"gzip\",\n",
    "        parse_dates=[\"Date\"],\n",
    "        dtype={\"FIPS\": str},\n",
    "    )\n",
    "\n",
    "    # rename pm25 concentration columns in years that they are inconsistent with the rest\n",
    "    if year in [2015, 2016]:\n",
    "        dfy = dfy.rename(\n",
    "            {\n",
    "                \"Prediction\": \"pm25_daily_average(ug/m3)\",\n",
    "                \"SEpred\": \"pm25_daily_average_stderr(ug/m3)\",\n",
    "                \"Loc_Label1\": \"FIPS\",\n",
    "            },\n",
    "            axis=\"columns\",\n",
    "        )\n",
    "        dfy[\"FIPS\"] = dfy[\"FIPS\"].astype(str)\n",
    "\n",
    "    dflist.append(dfy)\n",
    "\n",
    "dff_all = pd.concat(dflist)\n",
    "\n",
    "dff_all[\"year\"] = dff_all.Date.dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get annual average pm2.5\n",
    "dff_am_all = dff_all.groupby([\"FIPS\", \"year\"])[\"pm25_daily_average(ug/m3)\"].mean()\n",
    "dff_am_all.name = \"faqsd pm25\"\n",
    "\n",
    "# clean up FIPS code and align index with wildfire pm2.5 dataset\n",
    "dff_am_all = dff_am_all.reset_index()\n",
    "dff_am_all[\"FIPS\"] = dff_am_all[\"FIPS\"].str.strip().str.zfill(11)\n",
    "dff_am_all = dff_am_all.set_index([\"FIPS\", \"year\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfef = dfe.merge(\n",
    "    dff_am_all, left_on=[\"GEOID\", \"year\"], right_on=[\"FIPS\", \"year\"], how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate wildfire-specific PM2.5 fraction using Kirk Baker CMAQ outputs\n",
    "\n",
    "dfef[\"prop_wfpm25\"] = dfef[\"PM_wf\"] / dfef[\"PM_total\"]\n",
    "\n",
    "# recalculate wildfire-specific PM2.5 concentrations\n",
    "# using FAQSD data and Kirk Baker CMAQ outputs\n",
    "\n",
    "dfef[\"PM_wf\"] = dfef[\"prop_wfpm25\"] * dfef[\"faqsd pm25\"]\n",
    "dfef[\"PM_nofire\"] = dfef[\"faqsd pm25\"] - dfef[\"PM_wf\"]\n",
    "dfef[\"PM_total\"] = dfef[\"faqsd pm25\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. join wildfire pm predictions from childs et al"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfchilds = pd.read_csv(\n",
    "    \"C:\\\\Users\\\\rrice\\\\OneDrive - Environmental Protection Agency (EPA)\\\\exposure disparities\\\\childs et al data\\\\smokePM2pt5_predictions_daily_tract_20060101-20201231.csv\",\n",
    "    parse_dates=[\"date\"],\n",
    "    dtype={\"GEOID\": str},\n",
    ")\n",
    "\n",
    "# calculate annual average accounting for leap years\n",
    "\n",
    "dfchilds[\"year\"] = dfchilds[\"date\"].dt.year\n",
    "dfchilds[\"days_in_year\"] = 355\n",
    "dfchilds.loc[dfchilds[\"year\"].apply(calendar.isleap), \"days_in_year\"] = 366\n",
    "\n",
    "\n",
    "def mean_smokePM(df):\n",
    "    \"\"\"Calculate mean smoke PM for a given year, accounting for leap years.\"\"\"\n",
    "\n",
    "    return df[\"smokePM_pred\"].sum() / df[\"days_in_year\"].iloc[0]\n",
    "\n",
    "\n",
    "dfchilds_annmean = dfchilds.groupby([\"GEOID\", \"year\"]).apply(mean_smokePM)\n",
    "dfchilds_annmean.name = \"wfpm25_childs\"\n",
    "\n",
    "# join with cmaq data\n",
    "\n",
    "dfpm = dfef.set_index([\"GEOID\", \"year\"]).join(dfchilds_annmean, how=\"outer\")[\n",
    "    [\n",
    "        \"longitude\",\n",
    "        \"latitude\",\n",
    "        \"GISJOIN\",\n",
    "        \"PM_total\",\n",
    "        \"PM_nofire\",\n",
    "        \"PM_wf\",\n",
    "        \"wfpm25_childs\",\n",
    "    ]\n",
    "]\n",
    "dfpm\n",
    "\n",
    "# dfi.groupby(\"year\").plot.scatter(x=\"longitude\", y=\"latitude\", c=\"PM_total\", cmap=\"viridis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate r^2 between wildfire pm from cmaq and wildfire pm from childs et al\n",
    "dfpm[\"PM_wf\"].corr(dfpm[\"wfpm25_childs\"]) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfpm.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to intermediate data folder\n",
    "\n",
    "dfpm.to_csv(\n",
    "    \"C:\\\\Users\\\\rrice\\\\OneDrive - Environmental Protection Agency (EPA)\\\\exposure disparities\\\\thesis intermediate dataset\\\\census tract pm25 datasets 11-15-2023.csv\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geocube_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
