{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Analyses of areas with both high non-fire and fire PM2.5 concentrations.\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "from statsmodels.stats.weightstats import DescrStatsW\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas\n",
    "\n",
    "\n",
    "# set matplotlib/seaborn to 300dpi\n",
    "sns.set_context(\"paper\", font_scale=1.5, rc={\"figure.dpi\": 300})\n",
    "\n",
    "total_threshold = 9.6\n",
    "nofire_threshold = 8.7\n",
    "fire_threshold = 0.88"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"data/total + wildfire pm and demographic data 6-17-2024.parquet\")\n",
    "# reshape to calculate summary statistics for all years\n",
    "dfl = pd.wide_to_long(\n",
    "    df,\n",
    "    stubnames=[\"PM_total_\", \"PM_nofire_\", \"PM_wf_\", \"wfpm25_childs_\"],\n",
    "    i=[\"GISJOIN\"],\n",
    "    j=\"Year\",\n",
    ")\n",
    "# create correlation matrix for each pm dataset\n",
    "corr = dfl[[\"PM_total_\", \"PM_nofire_\", \"PM_wf_\", \"wfpm25_childs_\"]].corr()\n",
    "corr\n",
    "\n",
    "# calculate overall average pm25 concentration for each dataset for each tract\n",
    "overall_means = dfl.groupby(\"GISJOIN\")[\n",
    "    [\"PM_total_\", \"PM_nofire_\", \"PM_wf_\", \"wfpm25_childs_\"]\n",
    "].mean()\n",
    "\n",
    "overall_means.columns = [\n",
    "    \"CMAQ Total overall mean\",\n",
    "    \"CMAQ Non-fire overall mean\",\n",
    "    \"CMAQ Fire overall mean\",\n",
    "    \"Childs Fire overall mean\",\n",
    "]\n",
    "\n",
    "# join overall means to original dataframe\n",
    "df = df.join(overall_means, on=\"GISJOIN\")\n",
    "\n",
    "# make income quartile group a categorical variable\n",
    "df[\"Income quartile\"] = pd.Categorical(\n",
    "    df[\"Income quartile\"],\n",
    "    [1, 2, 3, 4],\n",
    "    ordered=True,\n",
    ")\n",
    "\n",
    "# get tracts where the overall mean is greater than the threshold concentration\n",
    "high_total_tracts = df[(df[\"CMAQ Total overall mean\"] > total_threshold)]\n",
    "\n",
    "# get tracts where the overall mean is greater than the threshold concentration\n",
    "high_nofire_tracts = df[(df[\"CMAQ Non-fire overall mean\"] > nofire_threshold)]\n",
    "\n",
    "# get tracts where the overall mean is greater than the threshold concentration\n",
    "high_fire_tracts = df[(df[\"CMAQ Fire overall mean\"] > fire_threshold)]\n",
    "\n",
    "# get tracts where both fire and nofire are greater than the threshold concentration\n",
    "high_both_tracts = df[\n",
    "    (df[\"CMAQ Non-fire overall mean\"] > nofire_threshold)\n",
    "    & (df[\"CMAQ Fire overall mean\"] > fire_threshold)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_language_distribution(df, name):\n",
    "    \"\"\"Calculate percent of population by language.\"\"\"\n",
    "    total = df[\"Total Population\"].sum()\n",
    "    df_summary = pd.DataFrame(\n",
    "        {\n",
    "            \"% Language spoken at home: only English\": df[\n",
    "                \"Language spoken at home: only English\"\n",
    "            ].sum()\n",
    "            / total\n",
    "            * 100,\n",
    "            \"% Language other than English spoken at home, speaks English well\": df[\n",
    "                \"Language other than English spoken at home, speaks English well\"\n",
    "            ].sum()\n",
    "            / total\n",
    "            * 100,\n",
    "            \"% Language other than English spoken at home, does not speak English well\": df[\n",
    "                \"Language other than English spoken at home, does not speak English well\"\n",
    "            ].sum()\n",
    "            / total\n",
    "            * 100,\n",
    "        },\n",
    "        index=[name],\n",
    "    )\n",
    "    return df_summary\n",
    "\n",
    "\n",
    "language_table = pd.concat(\n",
    "    [\n",
    "        calc_language_distribution(df, name=\"Overall\").round(1),\n",
    "        calc_language_distribution(high_nofire_tracts, name=\"High Non-fire\").round(1),\n",
    "        calc_language_distribution(high_fire_tracts, name=\"High Fire\").round(1),\n",
    "        calc_language_distribution(high_both_tracts, name=\"High Both\").round(1),\n",
    "    ]\n",
    ").T\n",
    "\n",
    "language_table[\"name\"] = \"Language spoken at home (%)\"\n",
    "language_table = language_table.reset_index().set_index([\"name\", \"index\"])\n",
    "language_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_region_distribution(df, name):\n",
    "    \"\"\"Calculate percent of population by RUCA.\"\"\"\n",
    "    region_distribution = (\n",
    "        df.groupby(\"NCA Region\")[\"Total Population\"].sum()\n",
    "        / df[\"Total Population\"].sum()\n",
    "        * 100\n",
    "    )\n",
    "    region_distribution.name = name\n",
    "    return region_distribution\n",
    "\n",
    "\n",
    "region_table = pd.DataFrame(\n",
    "    [\n",
    "        calc_region_distribution(df, name=\"Overall\").round(1),\n",
    "        calc_region_distribution(high_nofire_tracts, name=\"High Non-fire\").round(1),\n",
    "        calc_region_distribution(high_fire_tracts, name=\"High Fire\").round(1),\n",
    "        calc_region_distribution(high_both_tracts, name=\"High Both\").round(1),\n",
    "    ]\n",
    ").T\n",
    "\n",
    "region_table[\"name\"] = \"NCA Region (%)\"\n",
    "region_table.index.name = \"index\"\n",
    "region_table = region_table.reset_index().set_index([\"name\", \"index\"])\n",
    "region_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_ruca_distribution(df, name):\n",
    "    \"\"\"Calculate percent of population by RUCA.\"\"\"\n",
    "    ruca_distribution = (\n",
    "        df.groupby(\"RUCA 1\")[\"Total Population\"].sum()\n",
    "        / df[\"Total Population\"].sum()\n",
    "        * 100\n",
    "    )\n",
    "    ruca_distribution.name = name\n",
    "    return ruca_distribution\n",
    "\n",
    "\n",
    "ruca_table = pd.DataFrame(\n",
    "    [\n",
    "        calc_ruca_distribution(df, name=\"Overall\").round(1),\n",
    "        calc_ruca_distribution(high_nofire_tracts, name=\"High Non-fire\").round(1),\n",
    "        calc_ruca_distribution(high_fire_tracts, name=\"High Fire\").round(1),\n",
    "        calc_ruca_distribution(high_both_tracts, name=\"High Both\").round(1),\n",
    "    ]\n",
    ").T\n",
    "\n",
    "ruca_table[\"name\"] = \"RUCA (%)\"\n",
    "ruca_table = ruca_table.reset_index()\n",
    "ruca_table.rename(columns={\"RUCA 1\": \"index\"}, inplace=True)\n",
    "\n",
    "ruca_table[\"index\"] = pd.Categorical(\n",
    "    ruca_table[\"index\"],\n",
    "    [\"Urban core\", \"Suburban\", \"Micropolitan\", \"Small town\", \"Rural\"],\n",
    "    ordered=True,\n",
    ")\n",
    "\n",
    "ruca_table = ruca_table.sort_values(\"index\")\n",
    "\n",
    "ruca_table = ruca_table.reset_index().set_index([\"name\", \"index\"])\n",
    "ruca_table.drop(columns=\"level_0\", inplace=True)\n",
    "\n",
    "ruca_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_income_distribution(df, name):\n",
    "    \"\"\"Calculate percent of population in each income quartile.\"\"\"\n",
    "    income_distribution = (\n",
    "        df.groupby(\"Income quartile\", observed=True)[\"Total Population\"].sum()\n",
    "        / df[\"Total Population\"].sum()\n",
    "        * 100\n",
    "    )\n",
    "    income_distribution.name = name\n",
    "\n",
    "    return income_distribution\n",
    "\n",
    "\n",
    "income_table = pd.DataFrame(\n",
    "    [\n",
    "        calc_income_distribution(df, name=\"Overall\").round(1),\n",
    "        calc_income_distribution(high_nofire_tracts, name=\"High Non-fire\").round(1),\n",
    "        calc_income_distribution(high_fire_tracts, name=\"High Fire\").round(1),\n",
    "        calc_income_distribution(high_both_tracts, name=\"High Both\").round(1),\n",
    "    ]\n",
    ").T\n",
    "\n",
    "income_table[\"name\"] = \"Income quartile (%)\"\n",
    "income_table.index.name = \"index\"\n",
    "income_table = income_table.reset_index().set_index([\"name\", \"index\"])\n",
    "income_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_racial_ethnic_makeup(df, name):\n",
    "    \"\"\"Calculate total number of people and the racial/ethnic distribution.\"\"\"\n",
    "    total = df[\"Total Population\"].sum()\n",
    "    df_summary = pd.DataFrame(\n",
    "        {\n",
    "            \"Total count\": total,\n",
    "            \"White\": df[\"NH White\"].sum() / total * 100,\n",
    "            \"Black\": df[\"NH Black\"].sum() / total * 100,\n",
    "            \"Hispanic\": df[\"Hispanic\"].sum() / total * 100,\n",
    "            \"Asian\": df[\"NH Asian\"].sum() / total * 100,\n",
    "            \"AIAN\": df[\"NH American Indian and Alaska Native\"].sum() / total * 100,\n",
    "        },\n",
    "        index=[name],\n",
    "    )\n",
    "    return df_summary\n",
    "\n",
    "\n",
    "# table of tracts with high pm25, defined as greater than the nth percentile\n",
    "\n",
    "racial_ethnic_table = pd.concat(\n",
    "    [\n",
    "        calc_racial_ethnic_makeup(df, name=\"Overall\").round(1),\n",
    "        calc_racial_ethnic_makeup(high_nofire_tracts, name=\"High Non-fire\").round(1),\n",
    "        calc_racial_ethnic_makeup(high_fire_tracts, name=\"High Fire\").round(1),\n",
    "        calc_racial_ethnic_makeup(high_both_tracts, name=\"High Both\").round(1),\n",
    "    ]\n",
    ").T\n",
    "\n",
    "racial_ethnic_table[\"name\"] = \"Race and ethnicity (%)\"\n",
    "racial_ethnic_table = racial_ethnic_table.reset_index()\n",
    "racial_ethnic_table.sort_values(\"index\", inplace=True)\n",
    "# racial_ethnic_table.index.name = \"index\"\n",
    "racial_ethnic_table = (\n",
    "    racial_ethnic_table.reset_index()\n",
    "    .set_index([\"name\", \"index\"])\n",
    "    .drop(columns=\"level_0\")\n",
    ")\n",
    "racial_ethnic_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_table = pd.concat(\n",
    "    [region_table, ruca_table, racial_ethnic_table, language_table, income_table]\n",
    ")\n",
    "out_table.to_csv(\"tables/tableS2.csv\")\n",
    "out_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_shape = geopandas.GeoDataFrame(pd.read_pickle(\"temp/out_shape.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label tracts with high pm25\n",
    "\n",
    "out_shape[\"high_nofire_tracts\"] = out_shape.index.isin(high_nofire_tracts.index)\n",
    "out_shape[\"high_fire_tracts\"] = out_shape.index.isin(high_fire_tracts.index)\n",
    "out_shape[\"high_both_tracts\"] = out_shape.index.isin(high_both_tracts.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(6, 6))\n",
    "axs = axs.flatten()\n",
    "\n",
    "labels = [\"High non-fire PM₂.₅\", \"High fire PM₂.₅\", \"High fire & non-fire PM₂.₅\"]\n",
    "\n",
    "color_brewer_colors = [\"#1f78b4\", \"#a6cee3\", \"#33a02c\"]\n",
    "\n",
    "for i, x in enumerate([\"high_nofire_tracts\", \"high_fire_tracts\", \"high_both_tracts\"]):\n",
    "\n",
    "    cmap = LinearSegmentedColormap.from_list(\n",
    "        name=\"custom\", colors=[\"lightgray\", color_brewer_colors[i]]\n",
    "    )\n",
    "\n",
    "    out_shape.plot(x, ax=axs[i], cmap=cmap, antialiased=False)\n",
    "    axs[i].set_axis_off()\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# add legend\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "legend_elements = [\n",
    "    mpatches.Patch(facecolor=color_brewer_colors[i], label=labels[i]) for i in range(3)\n",
    "]\n",
    "\n",
    "_ = fig.legend(\n",
    "    handles=legend_elements,\n",
    "    loc=\"lower center\",\n",
    "    ncol=3,\n",
    "    bbox_to_anchor=(0.5, 0.35),\n",
    "    fontsize=8,\n",
    "    frameon=True,\n",
    ")\n",
    "\n",
    "fig.savefig(f\"figures/high_pm25_tracts_pop_weighted_mean_thresh.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what percentiles are the 9 ug/m3 values?\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "for year in range(2007, 2019):\n",
    "    print(f\"Year: {year}\")\n",
    "    print(stats.percentileofscore(out_shape[f\"PM_total_{year}\"].dropna(), 9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_bar_data = (\n",
    "    out_table.loc[out_table.index.get_level_values(0) == \"Race and ethnicity (%)\"]\n",
    "    .stack()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "#  drop total count values\n",
    "grouped_bar_data = grouped_bar_data[\n",
    "    ~grouped_bar_data[\"index\"].str.contains(\"Total count\")\n",
    "]\n",
    "\n",
    "grouped_bar_data.columns = [\"name\", \"index\", \"PM_threshold\", \"Percent\"]\n",
    "\n",
    "# # drop overall values\n",
    "# grouped_bar_data = grouped_bar_data[\n",
    "#     ~grouped_bar_data[\"PM_threshold\"].str.contains(\"Overall\")\n",
    "# ]\n",
    "\n",
    "grouped_bar_data[\"index\"] = (\n",
    "    grouped_bar_data[\"index\"]\n",
    "    .str.replace(\"% \", \"\")\n",
    "    .str.replace(\"NH \", \"\")\n",
    "    .str.replace(\"American Indian and Alaska Native\", \"AIAN\")\n",
    ")\n",
    "grouped_bar_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context(\"talk\", font_scale=1.3, rc={\"figure.dpi\": 300})\n",
    "\n",
    "\n",
    "fig = sns.catplot(\n",
    "    data=grouped_bar_data.sort_values(\"PM_threshold\", ascending=False),\n",
    "    kind=\"bar\",\n",
    "    x=\"PM_threshold\",\n",
    "    y=\"Percent\",\n",
    "    col=\"index\",\n",
    "    height=6,\n",
    "    aspect=0.55,\n",
    "    sharey=False,\n",
    "    palette=[\"gray\"] + color_brewer_colors,\n",
    ")\n",
    "\n",
    "# rotate x axis labels\n",
    "for ax in fig.axes.flat:\n",
    "    for label in ax.get_xticklabels():\n",
    "        label.set_rotation(60)\n",
    "        # anchor labels to the right\n",
    "        # label.set_horizontalalignment(\"right\")\n",
    "\n",
    "fig.set_titles(\"{col_name}\")\n",
    "\n",
    "# remove x axis label\n",
    "fig.set_xlabels(\"\")\n",
    "\n",
    "# set y axis to log scale\n",
    "fig.set(yscale=\"linear\")\n",
    "\n",
    "# set y axis labels\n",
    "fig.set_ylabels(\"Percent of population (%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
